{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOP02kBrSjQiBhcKo4ATvTy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rodayna-moamen/fraud_detection_project/blob/main/02_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5XdA2oxhuLZA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the train and test data\n",
        "train_df = pd.read_csv('/content/train_processed.csv')\n",
        "test_df = pd.read_csv('/content/test_processed.csv')\n",
        "\n",
        "# Inspect the first few rows of the train and test data\n",
        "print(train_df.head())\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_edHocWFuZJy",
        "outputId": "4042adc2-f98b-4bec-b8b3-a729175cfe90"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Provider  TotalClaims  UniquePatients  TotalReimbursed  AvgReimbursed  \\\n",
            "0  PRV51001           25              24           104640    4185.600000   \n",
            "1  PRV51003          132             117           605670    4588.409091   \n",
            "2  PRV51004          149             138            52170     350.134228   \n",
            "3  PRV51005         1165             495           280910     241.124464   \n",
            "4  PRV51007           72              58            33710     468.194444   \n",
            "\n",
            "   StdReimbursed  MaxReimbursed  MinReimbursed  TotalDeductible  \\\n",
            "0   10796.091144          42000             10           5340.0   \n",
            "1    7309.794729          57000              0          66286.0   \n",
            "2     689.963754           3300              0            310.0   \n",
            "3     491.556392           4080              0           3700.0   \n",
            "4    1433.769116          10000              0           3264.0   \n",
            "\n",
            "   AvgDeductible  ...  Cancer_Rate  ObstrPulmonary_Rate  Depression_Rate  \\\n",
            "0     213.600000  ...     0.200000             0.400000         0.360000   \n",
            "1     502.166667  ...     0.075758             0.310606         0.409091   \n",
            "2       2.080537  ...     0.107383             0.275168         0.422819   \n",
            "3       3.175966  ...     0.141631             0.253219         0.416309   \n",
            "4      45.333333  ...     0.166667             0.222222         0.402778   \n",
            "\n",
            "   Diabetes_Rate  IschemicHeart_Rate  Osteoporasis_Rate  \\\n",
            "0       0.840000            0.920000           0.240000   \n",
            "1       0.757576            0.848485           0.250000   \n",
            "2       0.704698            0.724832           0.328859   \n",
            "3       0.685837            0.768240           0.295279   \n",
            "4       0.680556            0.708333           0.291667   \n",
            "\n",
            "   rheumatoidarthritis_Rate  stroke_Rate  PotentialFraud  Fraud  \n",
            "0                  0.320000     0.240000              No      0  \n",
            "1                  0.287879     0.090909             Yes      1  \n",
            "2                  0.308725     0.114094              No      0  \n",
            "3                  0.284120     0.106438             Yes      1  \n",
            "4                  0.305556     0.166667              No      0  \n",
            "\n",
            "[5 rows x 29 columns]\n",
            "   Provider  TotalClaims  UniquePatients  TotalReimbursed  AvgReimbursed  \\\n",
            "0  PRV51002          205             169            53790     262.390244   \n",
            "1  PRV51006          102              81            30720     301.176471   \n",
            "2  PRV51009           39              30            27230     698.205128   \n",
            "3  PRV51010           38              25            64580    1699.473684   \n",
            "4  PRV51018          190             146            61620     324.315789   \n",
            "\n",
            "   StdReimbursed  MaxReimbursed  MinReimbursed  TotalDeductible  \\\n",
            "0     609.021752           6010              0            380.0   \n",
            "1     520.835760           2300              0              0.0   \n",
            "2    1934.691424          11000              0           1238.0   \n",
            "3    4480.813118          20000              0           5340.0   \n",
            "4     673.767191           3300              0            670.0   \n",
            "\n",
            "   AvgDeductible  ...  Heartfailure_Rate  KidneyDisease_Rate  Cancer_Rate  \\\n",
            "0       1.853659  ...           0.526829            0.351220     0.121951   \n",
            "1       0.000000  ...           0.676471            0.490196     0.147059   \n",
            "2      32.578947  ...           0.435897            0.487179     0.025641   \n",
            "3     144.324324  ...           0.605263            0.500000     0.184211   \n",
            "4       3.526316  ...           0.573684            0.489474     0.131579   \n",
            "\n",
            "   ObstrPulmonary_Rate  Depression_Rate  Diabetes_Rate  IschemicHeart_Rate  \\\n",
            "0             0.312195         0.443902       0.717073            0.736585   \n",
            "1             0.362745         0.519608       0.705882            0.764706   \n",
            "2             0.384615         0.333333       0.743590            0.794872   \n",
            "3             0.342105         0.473684       0.736842            0.736842   \n",
            "4             0.321053         0.452632       0.768421            0.710526   \n",
            "\n",
            "   Osteoporasis_Rate  rheumatoidarthritis_Rate  stroke_Rate  \n",
            "0           0.297561                  0.263415     0.092683  \n",
            "1           0.254902                  0.156863     0.078431  \n",
            "2           0.512821                  0.102564     0.076923  \n",
            "3           0.368421                  0.263158     0.131579  \n",
            "4           0.300000                  0.231579     0.068421  \n",
            "\n",
            "[5 rows x 27 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify numerical and categorical features\n",
        "numeric_features = train_df.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = train_df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Ensure the target column 'Fraud' is not included in the features for X\n",
        "if 'Fraud' in numeric_features:\n",
        "    numeric_features = numeric_features.drop('Fraud')\n",
        "elif 'Fraud' in categorical_features:\n",
        "    categorical_features = categorical_features.drop('Fraud')"
      ],
      "metadata": {
        "id": "V8TPGhaNulgU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing pipeline for numerical data\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),  # Handle missing values with mean imputation\n",
        "    ('scaler', StandardScaler())  # Standardize numerical features\n",
        "])\n",
        "\n",
        "# Preprocessing pipeline for categorical data\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  # Handle missing values\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
        "])\n",
        "\n",
        "# Combine both pipelines using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "5YRwM4CxuqM3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final preprocessing pipeline\n",
        "preprocessing_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])"
      ],
      "metadata": {
        "id": "0wqu9UZdusbl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define X and y\n",
        "X_train = train_df.drop(columns=['Fraud'])  # Features (excluding the target)\n",
        "y_train = train_df['Fraud']  # Target (Fraud labels)\n",
        "\n",
        "# Apply the preprocessing pipeline to X_train\n",
        "X_train_processed = preprocessing_pipeline.fit_transform(X_train)\n",
        "\n",
        "# Initialize SMOTE\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "\n",
        "# Apply SMOTE to balance the training data\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)\n",
        "\n",
        "# Check the class distribution after SMOTE\n",
        "print(\"Class distribution after SMOTE:\")\n",
        "print(pd.Series(y_train_resampled).value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TrirYI0uysJ",
        "outputId": "20b63a22-3c2e-4270-dec3-529771bd870e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution after SMOTE:\n",
            "Fraud\n",
            "0    4904\n",
            "1    4904\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the resampled training data into train and validation sets (80/20 split)\n",
        "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_resampled, y_train_resampled, test_size=0.2, random_state=42, stratify=y_train_resampled)\n",
        "\n",
        "# Check the shape of the splits\n",
        "print(X_train_final.shape, X_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKoS79_jvWWY",
        "outputId": "369db094-6432-482f-9f75-040a250da6de"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7846, 5438) (1962, 5438)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train Logistic Regression model\n",
        "lr_model = LogisticRegression(random_state=42)\n",
        "lr_model.fit(X_train_final, y_train_final)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_pred_lr = lr_model.predict(X_val)\n",
        "\n",
        "# Evaluate the Logistic Regression model\n",
        "print(\"Logistic Regression Metrics:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_val, y_pred_lr)}\")\n",
        "print(f\"Precision: {precision_score(y_val, y_pred_lr)}\")\n",
        "print(f\"Recall: {recall_score(y_val, y_pred_lr)}\")\n",
        "print(f\"F1 Score: {f1_score(y_val, y_pred_lr)}\")\n",
        "print(f\"ROC AUC: {roc_auc_score(y_val, y_pred_lr)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZjosDV_vkAE",
        "outputId": "31f1ca1a-6dd5-431c-847f-8602486e6411"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Metrics:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "ROC AUC: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train Decision Tree model\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train_final, y_train_final)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_pred_dt = dt_model.predict(X_val)\n",
        "\n",
        "# Evaluate the Decision Tree model\n",
        "print(\"Decision Tree Metrics:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_val, y_pred_dt)}\")\n",
        "print(f\"Precision: {precision_score(y_val, y_pred_dt)}\")\n",
        "print(f\"Recall: {recall_score(y_val, y_pred_dt)}\")\n",
        "print(f\"F1 Score: {f1_score(y_val, y_pred_dt)}\")\n",
        "print(f\"ROC AUC: {roc_auc_score(y_val, y_pred_dt)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y55VGwCKvmmU",
        "outputId": "e5787528-3696-44de-8a7d-1eb63a995034"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Metrics:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "ROC AUC: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def evaluate_model(model, X_val, y_val):\n",
        "    y_pred = model.predict(X_val)\n",
        "    print(f\"Accuracy: {accuracy_score(y_val, y_pred)}\")\n",
        "    print(f\"Precision: {precision_score(y_val, y_pred)}\")\n",
        "    print(f\"Recall: {recall_score(y_val, y_pred)}\")\n",
        "    print(f\"F1 Score: {f1_score(y_val, y_pred)}\")\n",
        "    print(f\"ROC AUC: {roc_auc_score(y_val, y_pred)}\")\n",
        "\n",
        "# Evaluate Logistic Regression and Decision Tree\n",
        "evaluate_model(lr_model, X_val, y_val)\n",
        "evaluate_model(dt_model, X_val, y_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TinNx70DvqN-",
        "outputId": "872ea144-cbf2-4364-9c09-4e259a775832"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "ROC AUC: 1.0\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n",
            "ROC AUC: 1.0\n"
          ]
        }
      ]
    }
  ]
}